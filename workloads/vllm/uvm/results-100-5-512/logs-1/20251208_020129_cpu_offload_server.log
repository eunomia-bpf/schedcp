INFO 12-08 02:01:30 [__init__.py:216] Automatically detected platform cuda.
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:01:32 [api_server.py:1839] vLLM API server version 0.11.0rc2.dev37+g0efd540db.d20251126
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:01:32 [utils.py:233] non-default args: {'model_tag': 'Qwen/Qwen3-30B-A3B-FP8', 'model': 'Qwen/Qwen3-30B-A3B-FP8', 'enforce_eager': True, 'cpu_offload_gb': 8.0}
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:01:33 [model.py:552] Resolved architecture: Qwen3MoeForCausalLM
[1;36m(APIServer pid=472534)[0;0m `torch_dtype` is deprecated! Use `dtype` instead!
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:01:33 [model.py:1515] Using max model len 40960
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:01:33 [scheduler.py:205] Chunked prefill is enabled with max_num_batched_tokens=2048.
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:01:33 [__init__.py:382] Cudagraph is disabled under eager mode
INFO 12-08 02:01:35 [__init__.py:216] Automatically detected platform cuda.
[1;36m(EngineCore_DP0 pid=472656)[0;0m INFO 12-08 02:01:36 [core.py:648] Waiting for init message from front-end.
[1;36m(EngineCore_DP0 pid=472656)[0;0m INFO 12-08 02:01:36 [core.py:78] Initializing a V1 LLM engine (v0.11.0rc2.dev37+g0efd540db.d20251126) with config: model='Qwen/Qwen3-30B-A3B-FP8', speculative_config=None, tokenizer='Qwen/Qwen3-30B-A3B-FP8', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=fp8, enforce_eager=True, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-30B-A3B-FP8, enable_prefix_caching=True, chunked_prefill_enabled=True, pooler_config=None, compilation_config={"level":0,"debug_dump_path":null,"cache_dir":"","backend":"","custom_ops":[],"splitting_ops":null,"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":0,"use_cudagraph":false,"cudagraph_num_of_warmups":0,"cudagraph_capture_sizes":[],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"use_inductor_graph_partition":false,"pass_config":{},"max_capture_size":0,"local_cache_dir":null}
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=472656)[0;0m INFO 12-08 02:01:36 [parallel_state.py:1208] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=472656)[0;0m WARNING 12-08 02:01:37 [topk_topp_sampler.py:66] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(EngineCore_DP0 pid=472656)[0;0m INFO 12-08 02:01:37 [gpu_model_runner.py:2679] Starting to load model Qwen/Qwen3-30B-A3B-FP8...
[1;36m(EngineCore_DP0 pid=472656)[0;0m INFO 12-08 02:01:37 [gpu_model_runner.py:2711] Loading model from scratch...
[1;36m(EngineCore_DP0 pid=472656)[0;0m INFO 12-08 02:01:37 [cuda.py:367] Using Flash Attention backend on V1 engine.
[1;36m(EngineCore_DP0 pid=472656)[0;0m WARNING 12-08 02:01:37 [fp8.py:457] Failed to import DeepGemm kernels.
[1;36m(EngineCore_DP0 pid=472656)[0;0m WARNING 12-08 02:01:37 [fp8.py:480] CutlassBlockScaledGroupedGemm not supported on the current platform.
[1;36m(EngineCore_DP0 pid=472656)[0;0m INFO 12-08 02:01:39 [weight_utils.py:392] Using model weights format ['*.safetensors']
[1;36m(EngineCore_DP0 pid=472656)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/7 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=472656)[0;0m Loading safetensors checkpoint shards:  14% Completed | 1/7 [00:00<00:02,  2.02it/s]
[1;36m(EngineCore_DP0 pid=472656)[0;0m Loading safetensors checkpoint shards:  29% Completed | 2/7 [00:01<00:02,  1.70it/s]
[1;36m(EngineCore_DP0 pid=472656)[0;0m Loading safetensors checkpoint shards:  43% Completed | 3/7 [00:02<00:03,  1.23it/s]
[1;36m(EngineCore_DP0 pid=472656)[0;0m Loading safetensors checkpoint shards:  57% Completed | 4/7 [00:02<00:01,  1.65it/s]
[1;36m(EngineCore_DP0 pid=472656)[0;0m Loading safetensors checkpoint shards:  71% Completed | 5/7 [00:03<00:01,  1.61it/s]
[1;36m(EngineCore_DP0 pid=472656)[0;0m Loading safetensors checkpoint shards:  86% Completed | 6/7 [00:03<00:00,  1.57it/s]
[1;36m(EngineCore_DP0 pid=472656)[0;0m Loading safetensors checkpoint shards: 100% Completed | 7/7 [00:04<00:00,  1.54it/s]
[1;36m(EngineCore_DP0 pid=472656)[0;0m Loading safetensors checkpoint shards: 100% Completed | 7/7 [00:04<00:00,  1.55it/s]
[1;36m(EngineCore_DP0 pid=472656)[0;0m 
[1;36m(EngineCore_DP0 pid=472656)[0;0m INFO 12-08 02:01:44 [default_loader.py:267] Loading weights took 4.54 seconds
[1;36m(EngineCore_DP0 pid=472656)[0;0m INFO 12-08 02:01:44 [gpu_model_runner.py:2730] Model loading took 20.9151 GiB and 7.237077 seconds
[1;36m(EngineCore_DP0 pid=472656)[0;0m WARNING 12-08 02:01:44 [fused_moe.py:798] Using default MoE config. Performance might be sub-optimal! Config file not found at ['/home/yunwei37/workspace/vllm/vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_GeForce_RTX_5090,dtype=fp8_w8a8,block_shape=[128,128].json']
[1;36m(EngineCore_DP0 pid=472656)[0;0m INFO 12-08 02:01:46 [gpu_worker.py:313] Available KV cache memory: 5.81 GiB
[1;36m(EngineCore_DP0 pid=472656)[0;0m INFO 12-08 02:01:47 [kv_cache_utils.py:1121] GPU KV cache size: 63,440 tokens
[1;36m(EngineCore_DP0 pid=472656)[0;0m INFO 12-08 02:01:47 [kv_cache_utils.py:1125] Maximum concurrency for 40,960 tokens per request: 1.55x
[1;36m(EngineCore_DP0 pid=472656)[0;0m WARNING 12-08 02:01:47 [cudagraph_dispatcher.py:105] cudagraph dispatching keys are not initialized. No cudagraph will be used.
[1;36m(EngineCore_DP0 pid=472656)[0;0m INFO 12-08 02:01:47 [core.py:211] init engine (profile, create kv cache, warmup model) took 2.49 seconds
[1;36m(EngineCore_DP0 pid=472656)[0;0m INFO 12-08 02:01:47 [__init__.py:382] Cudagraph is disabled under eager mode
[1;36m(EngineCore_DP0 pid=472656)[0;0m INFO 12-08 02:01:48 [gc_utils.py:41] GC Debug Config. enabled:False,top_objects:-1
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:01:48 [loggers.py:147] Engine 000: vllm cache_config_info with initialization after num_gpu_blocks is: 3965
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:01:48 [api_server.py:1634] Supported_tasks: ['generate']
[1;36m(APIServer pid=472534)[0;0m WARNING 12-08 02:01:48 [model.py:1394] Default sampling parameters have been overridden by the model's Hugging Face generation config recommended from the model creator. If this is not intended, please relaunch vLLM instance with `--generation-config vllm`.
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:01:48 [serving_responses.py:137] Using default chat sampling params from model: {'temperature': 0.6, 'top_k': 20, 'top_p': 0.95}
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:01:48 [serving_chat.py:139] Using default chat sampling params from model: {'temperature': 0.6, 'top_k': 20, 'top_p': 0.95}
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:01:48 [serving_completion.py:76] Using default completion sampling params from model: {'temperature': 0.6, 'top_k': 20, 'top_p': 0.95}
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:01:48 [api_server.py:1912] Starting vLLM API server 0 on http://0.0.0.0:8000
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:01:48 [launcher.py:34] Available routes are:
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:01:48 [launcher.py:42] Route: /openapi.json, Methods: HEAD, GET
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:01:48 [launcher.py:42] Route: /docs, Methods: HEAD, GET
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:01:48 [launcher.py:42] Route: /docs/oauth2-redirect, Methods: HEAD, GET
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:01:48 [launcher.py:42] Route: /redoc, Methods: HEAD, GET
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:01:48 [launcher.py:42] Route: /health, Methods: GET
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:01:48 [launcher.py:42] Route: /load, Methods: GET
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:01:48 [launcher.py:42] Route: /ping, Methods: POST
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:01:48 [launcher.py:42] Route: /ping, Methods: GET
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:01:48 [launcher.py:42] Route: /tokenize, Methods: POST
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:01:48 [launcher.py:42] Route: /detokenize, Methods: POST
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:01:48 [launcher.py:42] Route: /v1/models, Methods: GET
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:01:48 [launcher.py:42] Route: /version, Methods: GET
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:01:48 [launcher.py:42] Route: /v1/responses, Methods: POST
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:01:48 [launcher.py:42] Route: /v1/responses/{response_id}, Methods: GET
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:01:48 [launcher.py:42] Route: /v1/responses/{response_id}/cancel, Methods: POST
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:01:48 [launcher.py:42] Route: /v1/chat/completions, Methods: POST
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:01:48 [launcher.py:42] Route: /v1/completions, Methods: POST
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:01:48 [launcher.py:42] Route: /v1/embeddings, Methods: POST
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:01:48 [launcher.py:42] Route: /pooling, Methods: POST
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:01:48 [launcher.py:42] Route: /classify, Methods: POST
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:01:48 [launcher.py:42] Route: /score, Methods: POST
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:01:48 [launcher.py:42] Route: /v1/score, Methods: POST
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:01:48 [launcher.py:42] Route: /v1/audio/transcriptions, Methods: POST
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:01:48 [launcher.py:42] Route: /v1/audio/translations, Methods: POST
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:01:48 [launcher.py:42] Route: /rerank, Methods: POST
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:01:48 [launcher.py:42] Route: /v1/rerank, Methods: POST
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:01:48 [launcher.py:42] Route: /v2/rerank, Methods: POST
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:01:48 [launcher.py:42] Route: /scale_elastic_ep, Methods: POST
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:01:48 [launcher.py:42] Route: /is_scaling_elastic_ep, Methods: POST
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:01:48 [launcher.py:42] Route: /invocations, Methods: POST
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:01:48 [launcher.py:42] Route: /metrics, Methods: GET
[1;36m(APIServer pid=472534)[0;0m INFO:     Started server process [472534]
[1;36m(APIServer pid=472534)[0;0m INFO:     Waiting for application startup.
[1;36m(APIServer pid=472534)[0;0m INFO:     Application startup complete.
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:48984 - "GET /health HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:48998 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:48998 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:01:58 [loggers.py:127] Engine 000: Avg prompt throughput: 139.8 tokens/s, Avg generation throughput: 12.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.2%, Prefix cache hit rate: 49.4%
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:59868 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:59870 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:59878 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:59888 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:59904 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:59914 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:59916 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:59920 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:59936 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:59950 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:59954 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:59956 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:59936 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:59972 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:59982 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:59984 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:59992 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:60008 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:60010 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:60024 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:60034 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:60040 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:60052 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:60064 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:60072 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:60082 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:60096 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:60104 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:60106 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:60110 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:60124 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:60136 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:60144 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:60158 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:60170 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:60178 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:60188 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:60204 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:60212 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:60224 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:60228 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:60232 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:60242 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:60258 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:60274 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:60288 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:60294 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:60298 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:60310 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:40066 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:02:08 [loggers.py:127] Engine 000: Avg prompt throughput: 1161.6 tokens/s, Avg generation throughput: 50.1 tokens/s, Running: 49 reqs, Waiting: 0 reqs, GPU KV cache usage: 19.5%, Prefix cache hit rate: 5.5%
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:60124 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:60052 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:60224 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:60232 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:60170 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:40078 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:40090 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:40092 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:60298 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:40102 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:40116 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:40132 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:40144 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:40152 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:60178 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:60052 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:40164 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:40176 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:40190 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:60008 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:40192 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:40202 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:40210 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:59956 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:60082 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:60106 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:40212 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:40220 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:60034 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:59984 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:40232 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:40248 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:40256 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:40272 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:40284 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:40294 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:40296 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:40312 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:40326 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:40338 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:40354 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:40366 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:40372 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:40384 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:60310 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:59982 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:44746 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:44754 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO:     127.0.0.1:44760 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:02:18 [loggers.py:127] Engine 000: Avg prompt throughput: 786.6 tokens/s, Avg generation throughput: 215.3 tokens/s, Running: 79 reqs, Waiting: 0 reqs, GPU KV cache usage: 26.4%, Prefix cache hit rate: 3.4%
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:02:28 [loggers.py:127] Engine 000: Avg prompt throughput: 135.4 tokens/s, Avg generation throughput: 357.2 tokens/s, Running: 61 reqs, Waiting: 0 reqs, GPU KV cache usage: 21.1%, Prefix cache hit rate: 3.2%
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:02:38 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 325.2 tokens/s, Running: 56 reqs, Waiting: 0 reqs, GPU KV cache usage: 23.8%, Prefix cache hit rate: 3.2%
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:02:48 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 289.3 tokens/s, Running: 48 reqs, Waiting: 0 reqs, GPU KV cache usage: 24.5%, Prefix cache hit rate: 3.2%
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:02:58 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 254.9 tokens/s, Running: 42 reqs, Waiting: 0 reqs, GPU KV cache usage: 25.3%, Prefix cache hit rate: 3.2%
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:03:08 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 229.9 tokens/s, Running: 36 reqs, Waiting: 0 reqs, GPU KV cache usage: 25.8%, Prefix cache hit rate: 3.2%
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:03:18 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 202.7 tokens/s, Running: 29 reqs, Waiting: 0 reqs, GPU KV cache usage: 23.4%, Prefix cache hit rate: 3.2%
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:03:28 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 167.1 tokens/s, Running: 20 reqs, Waiting: 0 reqs, GPU KV cache usage: 18.9%, Prefix cache hit rate: 3.2%
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:03:38 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 139.8 tokens/s, Running: 15 reqs, Waiting: 0 reqs, GPU KV cache usage: 15.7%, Prefix cache hit rate: 3.2%
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:03:48 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 115.9 tokens/s, Running: 10 reqs, Waiting: 0 reqs, GPU KV cache usage: 12.8%, Prefix cache hit rate: 3.2%
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:03:58 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 93.5 tokens/s, Running: 7 reqs, Waiting: 0 reqs, GPU KV cache usage: 10.9%, Prefix cache hit rate: 3.2%
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:04:08 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 54.2 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 2.2%, Prefix cache hit rate: 3.2%
[1;36m(APIServer pid=472534)[0;0m INFO 12-08 02:04:11 [launcher.py:99] Shutting down FastAPI HTTP server.
[1;36m(APIServer pid=472534)[0;0m INFO:     Shutting down
[1;36m(APIServer pid=472534)[0;0m INFO:     Waiting for application shutdown.
[1;36m(APIServer pid=472534)[0;0m INFO:     Application shutdown complete.
