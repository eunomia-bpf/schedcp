INFO 12-07 23:17:46 [__init__.py:216] Automatically detected platform cuda.
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:17:48 [api_server.py:1839] vLLM API server version 0.11.0rc2.dev37+g0efd540db.d20251126
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:17:48 [utils.py:233] non-default args: {'model_tag': 'Qwen/Qwen3-30B-A3B-FP8', 'model': 'Qwen/Qwen3-30B-A3B-FP8', 'enforce_eager': True, 'cpu_offload_gb': 8.0}
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:17:48 [model.py:552] Resolved architecture: Qwen3MoeForCausalLM
[1;36m(APIServer pid=393138)[0;0m `torch_dtype` is deprecated! Use `dtype` instead!
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:17:48 [model.py:1515] Using max model len 40960
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:17:49 [scheduler.py:205] Chunked prefill is enabled with max_num_batched_tokens=2048.
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:17:49 [__init__.py:382] Cudagraph is disabled under eager mode
INFO 12-07 23:17:51 [__init__.py:216] Automatically detected platform cuda.
[1;36m(EngineCore_DP0 pid=393295)[0;0m INFO 12-07 23:17:52 [core.py:648] Waiting for init message from front-end.
[1;36m(EngineCore_DP0 pid=393295)[0;0m INFO 12-07 23:17:52 [core.py:78] Initializing a V1 LLM engine (v0.11.0rc2.dev37+g0efd540db.d20251126) with config: model='Qwen/Qwen3-30B-A3B-FP8', speculative_config=None, tokenizer='Qwen/Qwen3-30B-A3B-FP8', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=fp8, enforce_eager=True, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-30B-A3B-FP8, enable_prefix_caching=True, chunked_prefill_enabled=True, pooler_config=None, compilation_config={"level":0,"debug_dump_path":null,"cache_dir":"","backend":"","custom_ops":[],"splitting_ops":null,"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":0,"use_cudagraph":false,"cudagraph_num_of_warmups":0,"cudagraph_capture_sizes":[],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"use_inductor_graph_partition":false,"pass_config":{},"max_capture_size":0,"local_cache_dir":null}
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=393295)[0;0m INFO 12-07 23:17:52 [parallel_state.py:1208] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=393295)[0;0m WARNING 12-07 23:17:52 [topk_topp_sampler.py:66] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(EngineCore_DP0 pid=393295)[0;0m INFO 12-07 23:17:52 [gpu_model_runner.py:2679] Starting to load model Qwen/Qwen3-30B-A3B-FP8...
[1;36m(EngineCore_DP0 pid=393295)[0;0m INFO 12-07 23:17:53 [gpu_model_runner.py:2711] Loading model from scratch...
[1;36m(EngineCore_DP0 pid=393295)[0;0m INFO 12-07 23:17:53 [cuda.py:367] Using Flash Attention backend on V1 engine.
[1;36m(EngineCore_DP0 pid=393295)[0;0m WARNING 12-07 23:17:53 [fp8.py:457] Failed to import DeepGemm kernels.
[1;36m(EngineCore_DP0 pid=393295)[0;0m WARNING 12-07 23:17:53 [fp8.py:480] CutlassBlockScaledGroupedGemm not supported on the current platform.
[1;36m(EngineCore_DP0 pid=393295)[0;0m INFO 12-07 23:17:55 [weight_utils.py:392] Using model weights format ['*.safetensors']
[1;36m(EngineCore_DP0 pid=393295)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/7 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=393295)[0;0m Loading safetensors checkpoint shards:  14% Completed | 1/7 [00:00<00:02,  2.04it/s]
[1;36m(EngineCore_DP0 pid=393295)[0;0m Loading safetensors checkpoint shards:  29% Completed | 2/7 [00:01<00:02,  1.70it/s]
[1;36m(EngineCore_DP0 pid=393295)[0;0m Loading safetensors checkpoint shards:  43% Completed | 3/7 [00:01<00:02,  1.72it/s]
[1;36m(EngineCore_DP0 pid=393295)[0;0m Loading safetensors checkpoint shards:  57% Completed | 4/7 [00:02<00:01,  2.12it/s]
[1;36m(EngineCore_DP0 pid=393295)[0;0m Loading safetensors checkpoint shards:  71% Completed | 5/7 [00:02<00:01,  1.88it/s]
[1;36m(EngineCore_DP0 pid=393295)[0;0m Loading safetensors checkpoint shards:  86% Completed | 6/7 [00:03<00:00,  1.73it/s]
[1;36m(EngineCore_DP0 pid=393295)[0;0m Loading safetensors checkpoint shards: 100% Completed | 7/7 [00:03<00:00,  1.65it/s]
[1;36m(EngineCore_DP0 pid=393295)[0;0m Loading safetensors checkpoint shards: 100% Completed | 7/7 [00:03<00:00,  1.75it/s]
[1;36m(EngineCore_DP0 pid=393295)[0;0m 
[1;36m(EngineCore_DP0 pid=393295)[0;0m INFO 12-07 23:17:59 [default_loader.py:267] Loading weights took 4.03 seconds
[1;36m(EngineCore_DP0 pid=393295)[0;0m INFO 12-07 23:17:59 [gpu_model_runner.py:2730] Model loading took 20.9151 GiB and 6.710363 seconds
[1;36m(EngineCore_DP0 pid=393295)[0;0m WARNING 12-07 23:18:00 [fused_moe.py:798] Using default MoE config. Performance might be sub-optimal! Config file not found at ['/home/yunwei37/workspace/vllm/vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_GeForce_RTX_5090,dtype=fp8_w8a8,block_shape=[128,128].json']
[1;36m(EngineCore_DP0 pid=393295)[0;0m INFO 12-07 23:18:02 [gpu_worker.py:313] Available KV cache memory: 5.81 GiB
[1;36m(EngineCore_DP0 pid=393295)[0;0m INFO 12-07 23:18:02 [kv_cache_utils.py:1121] GPU KV cache size: 63,440 tokens
[1;36m(EngineCore_DP0 pid=393295)[0;0m INFO 12-07 23:18:02 [kv_cache_utils.py:1125] Maximum concurrency for 40,960 tokens per request: 1.55x
[1;36m(EngineCore_DP0 pid=393295)[0;0m WARNING 12-07 23:18:02 [cudagraph_dispatcher.py:105] cudagraph dispatching keys are not initialized. No cudagraph will be used.
[1;36m(EngineCore_DP0 pid=393295)[0;0m INFO 12-07 23:18:02 [core.py:211] init engine (profile, create kv cache, warmup model) took 2.48 seconds
[1;36m(EngineCore_DP0 pid=393295)[0;0m INFO 12-07 23:18:03 [__init__.py:382] Cudagraph is disabled under eager mode
[1;36m(EngineCore_DP0 pid=393295)[0;0m INFO 12-07 23:18:03 [gc_utils.py:41] GC Debug Config. enabled:False,top_objects:-1
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:18:03 [loggers.py:147] Engine 000: vllm cache_config_info with initialization after num_gpu_blocks is: 3965
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:18:03 [api_server.py:1634] Supported_tasks: ['generate']
[1;36m(APIServer pid=393138)[0;0m WARNING 12-07 23:18:03 [model.py:1394] Default sampling parameters have been overridden by the model's Hugging Face generation config recommended from the model creator. If this is not intended, please relaunch vLLM instance with `--generation-config vllm`.
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:18:03 [serving_responses.py:137] Using default chat sampling params from model: {'temperature': 0.6, 'top_k': 20, 'top_p': 0.95}
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:18:03 [serving_chat.py:139] Using default chat sampling params from model: {'temperature': 0.6, 'top_k': 20, 'top_p': 0.95}
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:18:03 [serving_completion.py:76] Using default completion sampling params from model: {'temperature': 0.6, 'top_k': 20, 'top_p': 0.95}
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:18:03 [api_server.py:1912] Starting vLLM API server 0 on http://0.0.0.0:8000
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:18:03 [launcher.py:34] Available routes are:
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:18:03 [launcher.py:42] Route: /openapi.json, Methods: HEAD, GET
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:18:03 [launcher.py:42] Route: /docs, Methods: HEAD, GET
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:18:03 [launcher.py:42] Route: /docs/oauth2-redirect, Methods: HEAD, GET
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:18:03 [launcher.py:42] Route: /redoc, Methods: HEAD, GET
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:18:03 [launcher.py:42] Route: /health, Methods: GET
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:18:03 [launcher.py:42] Route: /load, Methods: GET
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:18:03 [launcher.py:42] Route: /ping, Methods: POST
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:18:03 [launcher.py:42] Route: /ping, Methods: GET
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:18:03 [launcher.py:42] Route: /tokenize, Methods: POST
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:18:03 [launcher.py:42] Route: /detokenize, Methods: POST
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:18:03 [launcher.py:42] Route: /v1/models, Methods: GET
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:18:03 [launcher.py:42] Route: /version, Methods: GET
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:18:03 [launcher.py:42] Route: /v1/responses, Methods: POST
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:18:03 [launcher.py:42] Route: /v1/responses/{response_id}, Methods: GET
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:18:03 [launcher.py:42] Route: /v1/responses/{response_id}/cancel, Methods: POST
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:18:03 [launcher.py:42] Route: /v1/chat/completions, Methods: POST
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:18:03 [launcher.py:42] Route: /v1/completions, Methods: POST
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:18:03 [launcher.py:42] Route: /v1/embeddings, Methods: POST
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:18:03 [launcher.py:42] Route: /pooling, Methods: POST
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:18:03 [launcher.py:42] Route: /classify, Methods: POST
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:18:03 [launcher.py:42] Route: /score, Methods: POST
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:18:03 [launcher.py:42] Route: /v1/score, Methods: POST
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:18:03 [launcher.py:42] Route: /v1/audio/transcriptions, Methods: POST
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:18:03 [launcher.py:42] Route: /v1/audio/translations, Methods: POST
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:18:03 [launcher.py:42] Route: /rerank, Methods: POST
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:18:03 [launcher.py:42] Route: /v1/rerank, Methods: POST
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:18:03 [launcher.py:42] Route: /v2/rerank, Methods: POST
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:18:03 [launcher.py:42] Route: /scale_elastic_ep, Methods: POST
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:18:03 [launcher.py:42] Route: /is_scaling_elastic_ep, Methods: POST
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:18:03 [launcher.py:42] Route: /invocations, Methods: POST
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:18:03 [launcher.py:42] Route: /metrics, Methods: GET
[1;36m(APIServer pid=393138)[0;0m INFO:     Started server process [393138]
[1;36m(APIServer pid=393138)[0;0m INFO:     Waiting for application startup.
[1;36m(APIServer pid=393138)[0;0m INFO:     Application startup complete.
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:45110 - "GET /health HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55148 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:18:13 [loggers.py:127] Engine 000: Avg prompt throughput: 70.0 tokens/s, Avg generation throughput: 9.5 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.3%, Prefix cache hit rate: 0.0%
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:18:23 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 37.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.9%, Prefix cache hit rate: 0.0%
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55148 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:57716 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:57718 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:57734 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:57744 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:57746 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:57762 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:57776 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:57778 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:57782 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:57790 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:57802 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55176 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55180 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55188 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55190 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55194 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55200 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55210 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55220 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55226 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55236 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55244 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55252 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55262 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55266 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55270 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55280 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55282 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55294 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55296 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55312 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55316 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55330 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55332 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55338 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55342 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55350 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55352 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55360 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55362 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55366 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55368 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55378 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55392 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55396 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55398 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:18:33 [loggers.py:127] Engine 000: Avg prompt throughput: 1054.3 tokens/s, Avg generation throughput: 32.6 tokens/s, Running: 38 reqs, Waiting: 0 reqs, GPU KV cache usage: 17.9%, Prefix cache hit rate: 6.0%
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55408 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55416 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55424 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55428 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55444 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55446 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55452 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55460 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55474 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55478 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55494 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55502 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55516 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55530 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55544 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55558 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55562 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:55572 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:39604 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:39616 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:39630 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:39636 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:39642 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:39654 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:39660 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:39664 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:39674 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:39682 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:39698 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:39714 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:39718 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:39720 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:39728 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:39734 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:39750 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:39764 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:39770 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:39774 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:39790 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:39794 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:39800 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:39816 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:39830 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:39846 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:39848 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:18:43 [loggers.py:127] Engine 000: Avg prompt throughput: 1061.6 tokens/s, Avg generation throughput: 177.3 tokens/s, Running: 89 reqs, Waiting: 0 reqs, GPU KV cache usage: 37.6%, Prefix cache hit rate: 3.3%
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:39850 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:39860 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:39862 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:39864 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:39874 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:39886 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:39890 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO:     127.0.0.1:39900 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:18:53 [loggers.py:127] Engine 000: Avg prompt throughput: 234.1 tokens/s, Avg generation throughput: 438.0 tokens/s, Running: 100 reqs, Waiting: 0 reqs, GPU KV cache usage: 48.0%, Prefix cache hit rate: 3.0%
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:19:03 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 478.8 tokens/s, Running: 99 reqs, Waiting: 0 reqs, GPU KV cache usage: 54.8%, Prefix cache hit rate: 3.0%
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:19:13 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 475.2 tokens/s, Running: 99 reqs, Waiting: 0 reqs, GPU KV cache usage: 62.3%, Prefix cache hit rate: 3.0%
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:19:23 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 465.3 tokens/s, Running: 99 reqs, Waiting: 0 reqs, GPU KV cache usage: 69.7%, Prefix cache hit rate: 3.0%
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:19:33 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 475.0 tokens/s, Running: 99 reqs, Waiting: 0 reqs, GPU KV cache usage: 77.1%, Prefix cache hit rate: 3.0%
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:19:43 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 455.4 tokens/s, Running: 99 reqs, Waiting: 0 reqs, GPU KV cache usage: 84.4%, Prefix cache hit rate: 3.0%
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:19:53 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 465.3 tokens/s, Running: 99 reqs, Waiting: 0 reqs, GPU KV cache usage: 91.8%, Prefix cache hit rate: 3.0%
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:20:03 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 465.3 tokens/s, Running: 99 reqs, Waiting: 0 reqs, GPU KV cache usage: 99.2%, Prefix cache hit rate: 3.0%
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:20:13 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 437.3 tokens/s, Running: 91 reqs, Waiting: 7 reqs, GPU KV cache usage: 99.5%, Prefix cache hit rate: 3.0%
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:20:23 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 399.5 tokens/s, Running: 85 reqs, Waiting: 10 reqs, GPU KV cache usage: 97.6%, Prefix cache hit rate: 3.0%
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:20:33 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 227.5 tokens/s, Running: 27 reqs, Waiting: 0 reqs, GPU KV cache usage: 28.2%, Prefix cache hit rate: 3.0%
[1;36m(APIServer pid=393138)[0;0m WARNING 12-07 23:20:42 [launcher.py:96] port 8000 is used by process psutil.Process(pid=383795, name='vllm', status='sleeping') launched with command:
[1;36m(APIServer pid=393138)[0;0m WARNING 12-07 23:20:42 [launcher.py:96] /home/yunwei37/workspace/vllm/.venv/bin/python3 /home/yunwei37/workspace/vllm/.venv/bin/vllm serve Qwen/Qwen3-30B-A3B-FP8 --enforce-eager
[1;36m(APIServer pid=393138)[0;0m INFO 12-07 23:20:42 [launcher.py:99] Shutting down FastAPI HTTP server.
[1;36m(APIServer pid=393138)[0;0m INFO:     Shutting down
[1;36m(APIServer pid=393138)[0;0m INFO:     Waiting for application shutdown.
[1;36m(APIServer pid=393138)[0;0m INFO:     Application shutdown complete.
